{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "from vgg import VGG\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = {}\n",
    "trans['train'] = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "trans['test'] = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7285e3d15d10461c9a3c769f4c0c26d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-10-python.tar.gz to ./\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "Data = {}\n",
    "Data['train'] = datasets.CIFAR10(\n",
    "    root='./',train=True,transform=trans['train'],download=True\n",
    ")\n",
    "Data['test'] = datasets.CIFAR10(\n",
    "    root='./',train=False,transform=trans['test'],download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x:data.DataLoader(Data[x],batch_size=512,shuffle=True,num_workers=num_workers) for x in ['train','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG('VGG16')\n",
    "vgg = vgg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg.parameters(), lr=0.01,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer,[150,250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(init_epoch,num_epochs):\n",
    "    train_loss = []\n",
    "    test_acc = []\n",
    "    best_model = vgg.state_dict()\n",
    "    for epoch in range(init_epoch,num_epochs):\n",
    "        print('Epoch:',epoch)\n",
    "        epoch_train_loss = []\n",
    "        epoch_test_acc = 0\n",
    "        vgg.train()\n",
    "        for x,y in dataloaders['train']:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = vgg(x)\n",
    "            loss = criterion(out,y)\n",
    "            epoch_train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            del x,y\n",
    "        \n",
    "        scheduler.step()\n",
    "            \n",
    "        epoch_train_loss = mean(epoch_train_loss)\n",
    "            \n",
    "        vgg.eval()\n",
    "        accuracies = 0\n",
    "        for x,y in dataloaders['test']:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            out = vgg(x)\n",
    "            accuracies+= torch.sum(torch.argmax(nn.functional.softmax(out, dim=1), dim=1)==y).item()\n",
    "            del x,y\n",
    "            \n",
    "        epoch_test_acc = accuracies/len(Data['test'])\n",
    "        \n",
    "        train_loss.append(epoch_train_loss)\n",
    "        test_acc.append(epoch_test_acc)\n",
    "        \n",
    "        print('Loss:',epoch_train_loss,'Accuracy:',epoch_test_acc)\n",
    "        \n",
    "        if epoch==0:\n",
    "            best_model = vgg.state_dict()\n",
    "        else:\n",
    "            if epoch_test_acc == max(test_acc):\n",
    "                best_model = vgg.state_dict()\n",
    "        \n",
    "        torch.save(best_model,'BestModel.pth')\n",
    "        \n",
    "    return (train_loss,test_acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: 1.5341495920200736 Accuracy: 0.5799\n",
      "Epoch: 1\n",
      "Loss: 1.02727736867204 Accuracy: 0.6747\n",
      "Epoch: 2\n",
      "Loss: 0.8012745380401611 Accuracy: 0.7082\n",
      "Epoch: 3\n",
      "Loss: 0.6588711689929573 Accuracy: 0.7547\n",
      "Epoch: 4\n",
      "Loss: 0.5816594374423124 Accuracy: 0.7761\n",
      "Epoch: 5\n",
      "Loss: 0.5193708411284855 Accuracy: 0.7627\n",
      "Epoch: 6\n",
      "Loss: 0.4778398397017498 Accuracy: 0.7938\n",
      "Epoch: 7\n",
      "Loss: 0.43445264867373873 Accuracy: 0.807\n",
      "Epoch: 8\n",
      "Loss: 0.40074020928266096 Accuracy: 0.8226\n",
      "Epoch: 9\n",
      "Loss: 0.3684662987991255 Accuracy: 0.8309\n",
      "Epoch: 10\n",
      "Loss: 0.3425835059309492 Accuracy: 0.838\n",
      "Epoch: 11\n",
      "Loss: 0.32344281490968196 Accuracy: 0.8556\n",
      "Epoch: 12\n",
      "Loss: 0.29856888554534133 Accuracy: 0.8223\n",
      "Epoch: 13\n",
      "Loss: 0.2789645445894222 Accuracy: 0.7922\n",
      "Epoch: 14\n",
      "Loss: 0.26242311724594664 Accuracy: 0.8277\n",
      "Epoch: 15\n",
      "Loss: 0.252370078952945 Accuracy: 0.8282\n",
      "Epoch: 16\n",
      "Loss: 0.24091198204123243 Accuracy: 0.8602\n",
      "Epoch: 17\n",
      "Loss: 0.22121956807618237 Accuracy: 0.8483\n",
      "Epoch: 18\n",
      "Loss: 0.21023415211512117 Accuracy: 0.8552\n",
      "Epoch: 19\n",
      "Loss: 0.20141352393797465 Accuracy: 0.8505\n",
      "Epoch: 20\n",
      "Loss: 0.1889883708588931 Accuracy: 0.8604\n",
      "Epoch: 21\n",
      "Loss: 0.18087231322210662 Accuracy: 0.8633\n",
      "Epoch: 22\n",
      "Loss: 0.16808508769894132 Accuracy: 0.8634\n",
      "Epoch: 23\n",
      "Loss: 0.1619337293870595 Accuracy: 0.8655\n",
      "Epoch: 24\n",
      "Loss: 0.15467779627259898 Accuracy: 0.8695\n",
      "Epoch: 25\n",
      "Loss: 0.14050722213423983 Accuracy: 0.8716\n",
      "Epoch: 26\n",
      "Loss: 0.1383101692309185 Accuracy: 0.8647\n",
      "Epoch: 27\n",
      "Loss: 0.13253051521522657 Accuracy: 0.8733\n",
      "Epoch: 28\n",
      "Loss: 0.12056320517951129 Accuracy: 0.874\n",
      "Epoch: 29\n",
      "Loss: 0.11524311582348784 Accuracy: 0.8451\n",
      "Epoch: 30\n",
      "Loss: 0.11908049090784423 Accuracy: 0.875\n",
      "Epoch: 31\n",
      "Loss: 0.10643648656503278 Accuracy: 0.8702\n",
      "Epoch: 32\n",
      "Loss: 0.10408626755281371 Accuracy: 0.872\n",
      "Epoch: 33\n",
      "Loss: 0.09624234434901452 Accuracy: 0.8817\n",
      "Epoch: 34\n",
      "Loss: 0.10427900392334072 Accuracy: 0.8735\n",
      "Epoch: 35\n",
      "Loss: 0.08813772802906376 Accuracy: 0.8769\n",
      "Epoch: 36\n",
      "Loss: 0.08797922798869562 Accuracy: 0.8752\n",
      "Epoch: 37\n",
      "Loss: 0.08365798889830404 Accuracy: 0.8623\n",
      "Epoch: 38\n",
      "Loss: 0.08252928014464524 Accuracy: 0.8875\n",
      "Epoch: 39\n",
      "Loss: 0.08029225784144839 Accuracy: 0.8849\n",
      "Epoch: 40\n",
      "Loss: 0.07878003136387893 Accuracy: 0.8893\n",
      "Epoch: 41\n",
      "Loss: 0.07415135946048766 Accuracy: 0.8682\n",
      "Epoch: 42\n",
      "Loss: 0.07579278246480592 Accuracy: 0.8754\n",
      "Epoch: 43\n",
      "Loss: 0.06955471212918661 Accuracy: 0.8698\n",
      "Epoch: 44\n",
      "Loss: 0.06692223836268697 Accuracy: 0.8877\n",
      "Epoch: 45\n",
      "Loss: 0.06595106202424789 Accuracy: 0.8732\n",
      "Epoch: 46\n",
      "Loss: 0.06240447087935647 Accuracy: 0.8863\n",
      "Epoch: 47\n",
      "Loss: 0.05745713140967549 Accuracy: 0.8775\n",
      "Epoch: 48\n",
      "Loss: 0.05670495464333466 Accuracy: 0.8844\n",
      "Epoch: 49\n",
      "Loss: 0.05613309386357361 Accuracy: 0.8885\n",
      "Epoch: 50\n",
      "Loss: 0.06446734844345828 Accuracy: 0.8738\n",
      "Epoch: 51\n",
      "Loss: 0.05459908350389831 Accuracy: 0.8888\n",
      "Epoch: 52\n",
      "Loss: 0.05030910288724972 Accuracy: 0.8914\n",
      "Epoch: 53\n",
      "Loss: 0.048056691162744344 Accuracy: 0.8924\n",
      "Epoch: 54\n",
      "Loss: 0.0539429748848993 Accuracy: 0.8907\n",
      "Epoch: 55\n",
      "Loss: 0.04542663967122837 Accuracy: 0.8929\n",
      "Epoch: 56\n",
      "Loss: 0.04810181868319609 Accuracy: 0.8814\n",
      "Epoch: 57\n",
      "Loss: 0.048294217724885256 Accuracy: 0.8926\n",
      "Epoch: 58\n",
      "Loss: 0.04432268954851493 Accuracy: 0.8956\n",
      "Epoch: 59\n",
      "Loss: 0.040549613459377874 Accuracy: 0.8746\n",
      "Epoch: 60\n",
      "Loss: 0.04580361439789436 Accuracy: 0.8913\n",
      "Epoch: 61\n",
      "Loss: 0.04311571962067059 Accuracy: 0.8856\n",
      "Epoch: 62\n",
      "Loss: 0.043153668791815945 Accuracy: 0.8867\n",
      "Epoch: 63\n",
      "Loss: 0.04039389334086861 Accuracy: 0.8921\n",
      "Epoch: 64\n",
      "Loss: 0.03776981535234621 Accuracy: 0.8896\n",
      "Epoch: 65\n",
      "Loss: 0.038831072422314664 Accuracy: 0.8867\n",
      "Epoch: 66\n",
      "Loss: 0.046855163228298934 Accuracy: 0.8798\n",
      "Epoch: 67\n",
      "Loss: 0.03912702425173959 Accuracy: 0.8898\n",
      "Epoch: 68\n",
      "Loss: 0.03998249236076158 Accuracy: 0.8956\n",
      "Epoch: 69\n",
      "Loss: 0.033430552062559495 Accuracy: 0.8933\n",
      "Epoch: 70\n",
      "Loss: 0.03315820262710355 Accuracy: 0.8873\n",
      "Epoch: 71\n",
      "Loss: 0.03403483484206455 Accuracy: 0.8915\n",
      "Epoch: 72\n",
      "Loss: 0.03617810563431406 Accuracy: 0.89\n",
      "Epoch: 73\n",
      "Loss: 0.032099556510469744 Accuracy: 0.879\n",
      "Epoch: 74\n",
      "Loss: 0.03446525756307706 Accuracy: 0.8847\n",
      "Epoch: 75\n",
      "Loss: 0.03347831694124152 Accuracy: 0.8974\n",
      "Epoch: 76\n",
      "Loss: 0.028107581641144897 Accuracy: 0.8942\n",
      "Epoch: 77\n",
      "Loss: 0.032785609896693914 Accuracy: 0.9025\n",
      "Epoch: 78\n",
      "Loss: 0.03269856141842142 Accuracy: 0.8862\n",
      "Epoch: 79\n",
      "Loss: 0.028118271870082433 Accuracy: 0.8926\n",
      "Epoch: 80\n",
      "Loss: 0.03238564493058591 Accuracy: 0.8898\n",
      "Epoch: 81\n",
      "Loss: 0.028827326495808606 Accuracy: 0.8977\n",
      "Epoch: 82\n",
      "Loss: 0.026466965955701107 Accuracy: 0.8966\n",
      "Epoch: 83\n",
      "Loss: 0.03132037479164345 Accuracy: 0.8989\n",
      "Epoch: 84\n",
      "Loss: 0.026498277386536404 Accuracy: 0.8913\n",
      "Epoch: 85\n",
      "Loss: 0.024830312392085184 Accuracy: 0.9002\n",
      "Epoch: 86\n",
      "Loss: 0.028910771991145248 Accuracy: 0.9008\n",
      "Epoch: 87\n",
      "Loss: 0.029848392387585982 Accuracy: 0.903\n",
      "Epoch: 88\n",
      "Loss: 0.031999003555511635 Accuracy: 0.8976\n",
      "Epoch: 89\n",
      "Loss: 0.02645856706539587 Accuracy: 0.8972\n",
      "Epoch: 90\n",
      "Loss: 0.02550609309074222 Accuracy: 0.8956\n",
      "Epoch: 91\n",
      "Loss: 0.026684048918208907 Accuracy: 0.8848\n",
      "Epoch: 92\n",
      "Loss: 0.024027171202612167 Accuracy: 0.8966\n",
      "Epoch: 93\n",
      "Loss: 0.028017845270889147 Accuracy: 0.8888\n",
      "Epoch: 94\n",
      "Loss: 0.02802685974640962 Accuracy: 0.8918\n",
      "Epoch: 95\n",
      "Loss: 0.02821205688963587 Accuracy: 0.898\n",
      "Epoch: 96\n",
      "Loss: 0.026104067514023305 Accuracy: 0.8901\n",
      "Epoch: 97\n",
      "Loss: 0.02713440259804531 Accuracy: 0.9027\n",
      "Epoch: 98\n",
      "Loss: 0.023354140884832154 Accuracy: 0.8952\n",
      "Epoch: 99\n",
      "Loss: 0.027016949450255047 Accuracy: 0.8993\n",
      "Epoch: 100\n",
      "Loss: 0.02854799188920582 Accuracy: 0.8901\n",
      "Epoch: 101\n",
      "Loss: 0.027865173827324594 Accuracy: 0.8975\n",
      "Epoch: 102\n",
      "Loss: 0.02153223367141826 Accuracy: 0.8951\n",
      "Epoch: 103\n",
      "Loss: 0.022110664532804976 Accuracy: 0.9038\n",
      "Epoch: 104\n",
      "Loss: 0.02770343658096176 Accuracy: 0.8941\n",
      "Epoch: 105\n",
      "Loss: 0.020706452994740436 Accuracy: 0.8942\n",
      "Epoch: 106\n",
      "Loss: 0.020982665608503988 Accuracy: 0.9061\n",
      "Epoch: 107\n",
      "Loss: 0.022052126437691704 Accuracy: 0.8892\n",
      "Epoch: 108\n",
      "Loss: 0.02590889258937416 Accuracy: 0.8893\n",
      "Epoch: 109\n",
      "Loss: 0.02415566739854308 Accuracy: 0.9017\n",
      "Epoch: 110\n",
      "Loss: 0.020180439448212177 Accuracy: 0.9005\n",
      "Epoch: 111\n",
      "Loss: 0.02345581666319346 Accuracy: 0.8963\n",
      "Epoch: 112\n",
      "Loss: 0.022553257012207593 Accuracy: 0.899\n",
      "Epoch: 113\n",
      "Loss: 0.02154089940939935 Accuracy: 0.8925\n",
      "Epoch: 114\n",
      "Loss: 0.022229969396959155 Accuracy: 0.8934\n",
      "Epoch: 115\n",
      "Loss: 0.02148968697886686 Accuracy: 0.9004\n",
      "Epoch: 116\n",
      "Loss: 0.02532446383954767 Accuracy: 0.8951\n",
      "Epoch: 117\n",
      "Loss: 0.025615733335440864 Accuracy: 0.9006\n",
      "Epoch: 118\n",
      "Loss: 0.02436448938251302 Accuracy: 0.9034\n",
      "Epoch: 119\n",
      "Loss: 0.021781110793960338 Accuracy: 0.9\n",
      "Epoch: 120\n",
      "Loss: 0.021820286360132148 Accuracy: 0.9015\n",
      "Epoch: 121\n",
      "Loss: 0.023102848823847517 Accuracy: 0.896\n",
      "Epoch: 122\n",
      "Loss: 0.0226509472858921 Accuracy: 0.9017\n",
      "Epoch: 123\n",
      "Loss: 0.017812426182992603 Accuracy: 0.9039\n",
      "Epoch: 124\n",
      "Loss: 0.019851472323798403 Accuracy: 0.9011\n",
      "Epoch: 125\n",
      "Loss: 0.019758627716717974 Accuracy: 0.9001\n",
      "Epoch: 126\n",
      "Loss: 0.021542561848704914 Accuracy: 0.9013\n",
      "Epoch: 127\n",
      "Loss: 0.022694593575802082 Accuracy: 0.9054\n",
      "Epoch: 128\n",
      "Loss: 0.022232520241974568 Accuracy: 0.9052\n",
      "Epoch: 129\n",
      "Loss: 0.020594200048101495 Accuracy: 0.892\n",
      "Epoch: 130\n",
      "Loss: 0.018077343151125372 Accuracy: 0.8954\n",
      "Epoch: 131\n",
      "Loss: 0.0177476841205617 Accuracy: 0.9037\n",
      "Epoch: 132\n",
      "Loss: 0.018907012465428943 Accuracy: 0.8975\n",
      "Epoch: 133\n",
      "Loss: 0.022022480986138085 Accuracy: 0.9012\n",
      "Epoch: 134\n",
      "Loss: 0.01804530107397206 Accuracy: 0.9009\n",
      "Epoch: 135\n",
      "Loss: 0.02362679295736004 Accuracy: 0.897\n",
      "Epoch: 136\n",
      "Loss: 0.023222709834879757 Accuracy: 0.896\n",
      "Epoch: 137\n",
      "Loss: 0.021423796096778646 Accuracy: 0.9006\n",
      "Epoch: 138\n",
      "Loss: 0.016943118549237142 Accuracy: 0.9015\n",
      "Epoch: 139\n",
      "Loss: 0.01575152184434083 Accuracy: 0.9006\n",
      "Epoch: 140\n",
      "Loss: 0.01991216703888257 Accuracy: 0.8947\n",
      "Epoch: 141\n",
      "Loss: 0.020800396526821564 Accuracy: 0.8969\n",
      "Epoch: 142\n",
      "Loss: 0.02205278049223125 Accuracy: 0.9029\n",
      "Epoch: 143\n",
      "Loss: 0.01620867476342436 Accuracy: 0.9029\n",
      "Epoch: 144\n",
      "Loss: 0.020302250301845525 Accuracy: 0.9046\n",
      "Epoch: 145\n",
      "Loss: 0.01765871847675619 Accuracy: 0.9019\n",
      "Epoch: 146\n",
      "Loss: 0.01878664557993108 Accuracy: 0.9006\n",
      "Epoch: 147\n",
      "Loss: 0.017081407478497346 Accuracy: 0.9033\n",
      "Epoch: 148\n",
      "Loss: 0.018869839931781193 Accuracy: 0.8972\n",
      "Epoch: 149\n",
      "Loss: 0.02129407177622221 Accuracy: 0.8912\n",
      "Epoch: 150\n",
      "Loss: 0.01048413152469094 Accuracy: 0.9147\n",
      "Epoch: 151\n",
      "Loss: 0.005082327265491975 Accuracy: 0.9167\n",
      "Epoch: 152\n",
      "Loss: 0.004020798390099246 Accuracy: 0.9163\n",
      "Epoch: 153\n",
      "Loss: 0.0035320185902956115 Accuracy: 0.9182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 154\n",
      "Loss: 0.002878567434928133 Accuracy: 0.9176\n",
      "Epoch: 155\n",
      "Loss: 0.002564158876264962 Accuracy: 0.9186\n",
      "Epoch: 156\n",
      "Loss: 0.0026902308071635626 Accuracy: 0.9203\n",
      "Epoch: 157\n",
      "Loss: 0.0020762632763706985 Accuracy: 0.9193\n",
      "Epoch: 158\n",
      "Loss: 0.0021053998266603344 Accuracy: 0.9201\n",
      "Epoch: 159\n",
      "Loss: 0.0022897616192717484 Accuracy: 0.9199\n",
      "Epoch: 160\n",
      "Loss: 0.0017396779528971078 Accuracy: 0.9214\n",
      "Epoch: 161\n",
      "Loss: 0.001758775801507148 Accuracy: 0.9211\n",
      "Epoch: 162\n",
      "Loss: 0.001840171814309338 Accuracy: 0.9212\n",
      "Epoch: 163\n",
      "Loss: 0.0014718816281838 Accuracy: 0.9219\n",
      "Epoch: 164\n",
      "Loss: 0.0015691097535321262 Accuracy: 0.9217\n",
      "Epoch: 165\n",
      "Loss: 0.0014315696278164088 Accuracy: 0.9205\n",
      "Epoch: 166\n",
      "Loss: 0.0015378559711484276 Accuracy: 0.9213\n",
      "Epoch: 167\n",
      "Loss: 0.0014703027875523787 Accuracy: 0.9208\n",
      "Epoch: 168\n",
      "Loss: 0.0013748229791918695 Accuracy: 0.92\n",
      "Epoch: 169\n",
      "Loss: 0.0012821247233956938 Accuracy: 0.9202\n",
      "Epoch: 170\n",
      "Loss: 0.0013851311565044203 Accuracy: 0.9218\n",
      "Epoch: 171\n",
      "Loss: 0.001479116309735905 Accuracy: 0.9222\n",
      "Epoch: 172\n",
      "Loss: 0.001103084364535325 Accuracy: 0.9216\n",
      "Epoch: 173\n",
      "Loss: 0.0012438573119615453 Accuracy: 0.9214\n",
      "Epoch: 174\n",
      "Loss: 0.0009770822872844885 Accuracy: 0.9222\n",
      "Epoch: 175\n",
      "Loss: 0.0011310559962947415 Accuracy: 0.9218\n",
      "Epoch: 176\n",
      "Loss: 0.001038737245538386 Accuracy: 0.9219\n",
      "Epoch: 177\n",
      "Loss: 0.0009659583417803277 Accuracy: 0.9215\n",
      "Epoch: 178\n",
      "Loss: 0.0011006483780837866 Accuracy: 0.9216\n",
      "Epoch: 179\n",
      "Loss: 0.0009648182630724255 Accuracy: 0.9215\n",
      "Epoch: 180\n",
      "Loss: 0.000994877904452792 Accuracy: 0.9218\n",
      "Epoch: 181\n",
      "Loss: 0.0010361383388137293 Accuracy: 0.9223\n",
      "Epoch: 182\n",
      "Loss: 0.0009128642987165296 Accuracy: 0.9221\n",
      "Epoch: 183\n",
      "Loss: 0.0008496397601948975 Accuracy: 0.9225\n",
      "Epoch: 184\n",
      "Loss: 0.0009442302527568987 Accuracy: 0.9221\n",
      "Epoch: 185\n",
      "Loss: 0.0009324212520851336 Accuracy: 0.9222\n",
      "Epoch: 186\n",
      "Loss: 0.000817503530071212 Accuracy: 0.9223\n",
      "Epoch: 187\n",
      "Loss: 0.0008191729504353728 Accuracy: 0.9227\n",
      "Epoch: 188\n",
      "Loss: 0.0008451729841834428 Accuracy: 0.922\n",
      "Epoch: 189\n",
      "Loss: 0.0009124158793699224 Accuracy: 0.9221\n",
      "Epoch: 190\n",
      "Loss: 0.0008225809733445129 Accuracy: 0.9227\n",
      "Epoch: 191\n",
      "Loss: 0.000764393474852039 Accuracy: 0.9224\n",
      "Epoch: 192\n",
      "Loss: 0.0008861022554124154 Accuracy: 0.9222\n",
      "Epoch: 193\n",
      "Loss: 0.0008564704915684438 Accuracy: 0.9226\n",
      "Epoch: 194\n",
      "Loss: 0.0008607144531085898 Accuracy: 0.9235\n",
      "Epoch: 195\n",
      "Loss: 0.0009179899780250782 Accuracy: 0.9224\n",
      "Epoch: 196\n",
      "Loss: 0.0007306052141998685 Accuracy: 0.9217\n",
      "Epoch: 197\n",
      "Loss: 0.0007871520668101896 Accuracy: 0.9223\n",
      "Epoch: 198\n",
      "Loss: 0.0007527717822754034 Accuracy: 0.9225\n",
      "Epoch: 199\n",
      "Loss: 0.0007265567223004503 Accuracy: 0.9229\n",
      "Epoch: 200\n",
      "Loss: 0.0007687841306858677 Accuracy: 0.9229\n",
      "Epoch: 201\n",
      "Loss: 0.0006922206424749267 Accuracy: 0.9227\n",
      "Epoch: 202\n",
      "Loss: 0.0006347528762155574 Accuracy: 0.9228\n",
      "Epoch: 203\n",
      "Loss: 0.0006516568892224388 Accuracy: 0.9226\n",
      "Epoch: 204\n",
      "Loss: 0.0007069729337152759 Accuracy: 0.9233\n",
      "Epoch: 205\n",
      "Loss: 0.0007039826349664138 Accuracy: 0.9223\n",
      "Epoch: 206\n",
      "Loss: 0.000661202521230883 Accuracy: 0.9215\n",
      "Epoch: 207\n",
      "Loss: 0.0006362469424374819 Accuracy: 0.9225\n",
      "Epoch: 208\n",
      "Loss: 0.0006277642714106763 Accuracy: 0.9219\n",
      "Epoch: 209\n",
      "Loss: 0.0006201597784731385 Accuracy: 0.9211\n",
      "Epoch: 210\n",
      "Loss: 0.0005896461029342205 Accuracy: 0.9218\n",
      "Epoch: 211\n",
      "Loss: 0.000577103061635969 Accuracy: 0.9219\n",
      "Epoch: 212\n",
      "Loss: 0.0006155664597493027 Accuracy: 0.9218\n",
      "Epoch: 213\n",
      "Loss: 0.0006751043836963933 Accuracy: 0.9227\n",
      "Epoch: 214\n",
      "Loss: 0.0005673247663308961 Accuracy: 0.9222\n",
      "Epoch: 215\n",
      "Loss: 0.0006060917240778953 Accuracy: 0.9215\n",
      "Epoch: 216\n",
      "Loss: 0.0006095865320851457 Accuracy: 0.923\n",
      "Epoch: 217\n",
      "Loss: 0.0006017158991699962 Accuracy: 0.9217\n",
      "Epoch: 218\n",
      "Loss: 0.0006255719662829284 Accuracy: 0.9219\n",
      "Epoch: 219\n",
      "Loss: 0.0005712696827463425 Accuracy: 0.9218\n",
      "Epoch: 220\n",
      "Loss: 0.0006181279787430254 Accuracy: 0.9217\n",
      "Epoch: 221\n",
      "Loss: 0.000535262906442786 Accuracy: 0.9217\n",
      "Epoch: 222\n",
      "Loss: 0.0006042165721514813 Accuracy: 0.9214\n",
      "Epoch: 223\n",
      "Loss: 0.0005427094628411935 Accuracy: 0.9218\n",
      "Epoch: 224\n",
      "Loss: 0.0005512317406175164 Accuracy: 0.9216\n",
      "Epoch: 225\n",
      "Loss: 0.0005545957209673064 Accuracy: 0.9223\n",
      "Epoch: 226\n",
      "Loss: 0.0005589026340927302 Accuracy: 0.9222\n",
      "Epoch: 227\n",
      "Loss: 0.000533198143654902 Accuracy: 0.9224\n",
      "Epoch: 228\n",
      "Loss: 0.0005227781368041773 Accuracy: 0.9215\n",
      "Epoch: 229\n",
      "Loss: 0.0005859522273994469 Accuracy: 0.9221\n",
      "Epoch: 230\n",
      "Loss: 0.0005608609295747129 Accuracy: 0.9217\n",
      "Epoch: 231\n",
      "Loss: 0.0005040212864904399 Accuracy: 0.9221\n",
      "Epoch: 232\n",
      "Loss: 0.0004849044437703144 Accuracy: 0.9223\n",
      "Epoch: 233\n",
      "Loss: 0.0006446248295773961 Accuracy: 0.9223\n",
      "Epoch: 234\n",
      "Loss: 0.0004940959314604252 Accuracy: 0.9222\n",
      "Epoch: 235\n",
      "Loss: 0.0005576661918597409 Accuracy: 0.9226\n",
      "Epoch: 236\n",
      "Loss: 0.000548663326837265 Accuracy: 0.921\n",
      "Epoch: 237\n",
      "Loss: 0.000542351014125731 Accuracy: 0.9227\n",
      "Epoch: 238\n",
      "Loss: 0.000497911903503522 Accuracy: 0.9212\n",
      "Epoch: 239\n",
      "Loss: 0.0004109420863512371 Accuracy: 0.9215\n",
      "Epoch: 240\n",
      "Loss: 0.00047460733125893856 Accuracy: 0.9212\n",
      "Epoch: 241\n",
      "Loss: 0.0005016891087989836 Accuracy: 0.9213\n",
      "Epoch: 242\n",
      "Loss: 0.0004986835131659267 Accuracy: 0.9216\n",
      "Epoch: 243\n",
      "Loss: 0.0005341497015585761 Accuracy: 0.9218\n",
      "Epoch: 244\n",
      "Loss: 0.0005705914218382606 Accuracy: 0.9214\n",
      "Epoch: 245\n",
      "Loss: 0.0005122798403525459 Accuracy: 0.9213\n",
      "Epoch: 246\n",
      "Loss: 0.00046333534095426834 Accuracy: 0.9217\n",
      "Epoch: 247\n",
      "Loss: 0.0004863849375099989 Accuracy: 0.9214\n",
      "Epoch: 248\n",
      "Loss: 0.0004622592156864608 Accuracy: 0.9215\n",
      "Epoch: 249\n",
      "Loss: 0.0004508855658504941 Accuracy: 0.921\n",
      "Epoch: 250\n",
      "Loss: 0.00047599117756270026 Accuracy: 0.9219\n",
      "Epoch: 251\n",
      "Loss: 0.0004503376299648413 Accuracy: 0.9213\n",
      "Epoch: 252\n",
      "Loss: 0.0005112486827301279 Accuracy: 0.9202\n",
      "Epoch: 253\n",
      "Loss: 0.0005280634861116355 Accuracy: 0.9218\n",
      "Epoch: 254\n",
      "Loss: 0.000468808101556663 Accuracy: 0.9214\n",
      "Epoch: 255\n",
      "Loss: 0.0004887308627521448 Accuracy: 0.9212\n",
      "Epoch: 256\n",
      "Loss: 0.0004924286870530578 Accuracy: 0.9219\n",
      "Epoch: 257\n",
      "Loss: 0.00048492133943482815 Accuracy: 0.9216\n",
      "Epoch: 258\n",
      "Loss: 0.0004866614247902715 Accuracy: 0.9218\n",
      "Epoch: 259\n",
      "Loss: 0.0004491777642159628 Accuracy: 0.9216\n",
      "Epoch: 260\n",
      "Loss: 0.0005364616397632837 Accuracy: 0.9222\n",
      "Epoch: 261\n",
      "Loss: 0.0004254234295423922 Accuracy: 0.9214\n",
      "Epoch: 262\n",
      "Loss: 0.00042381288088164386 Accuracy: 0.9215\n",
      "Epoch: 263\n",
      "Loss: 0.0004625731088133168 Accuracy: 0.9215\n",
      "Epoch: 264\n",
      "Loss: 0.0003995038053716951 Accuracy: 0.9217\n",
      "Epoch: 265\n",
      "Loss: 0.0005025396532466997 Accuracy: 0.9216\n",
      "Epoch: 266\n",
      "Loss: 0.0004675369127653539 Accuracy: 0.9214\n",
      "Epoch: 267\n",
      "Loss: 0.00045893424486370796 Accuracy: 0.922\n",
      "Epoch: 268\n",
      "Loss: 0.0004752303701730407 Accuracy: 0.9211\n",
      "Epoch: 269\n",
      "Loss: 0.00046031904550582854 Accuracy: 0.9221\n",
      "Epoch: 270\n",
      "Loss: 0.0005241482836676628 Accuracy: 0.9208\n",
      "Epoch: 271\n",
      "Loss: 0.000502737534347665 Accuracy: 0.9228\n",
      "Epoch: 272\n",
      "Loss: 0.0004886632841032911 Accuracy: 0.9217\n",
      "Epoch: 273\n",
      "Loss: 0.0005318474632447908 Accuracy: 0.9215\n",
      "Epoch: 274\n",
      "Loss: 0.0005172156036548715 Accuracy: 0.9218\n",
      "Epoch: 275\n",
      "Loss: 0.00046488342581587673 Accuracy: 0.9214\n",
      "Epoch: 276\n",
      "Loss: 0.0004201633414688368 Accuracy: 0.9213\n",
      "Epoch: 277\n",
      "Loss: 0.0004363853240276364 Accuracy: 0.9214\n",
      "Epoch: 278\n",
      "Loss: 0.0004477976135047134 Accuracy: 0.9219\n",
      "Epoch: 279\n",
      "Loss: 0.0005231117645554168 Accuracy: 0.921\n",
      "Epoch: 280\n",
      "Loss: 0.00042995495697345623 Accuracy: 0.9213\n",
      "Epoch: 281\n",
      "Loss: 0.0004368711744639452 Accuracy: 0.9219\n",
      "Epoch: 282\n",
      "Loss: 0.00047793047893459776 Accuracy: 0.9216\n",
      "Epoch: 283\n",
      "Loss: 0.0004138134479907588 Accuracy: 0.9219\n",
      "Epoch: 284\n",
      "Loss: 0.0004786721150668775 Accuracy: 0.922\n",
      "Epoch: 285\n",
      "Loss: 0.0005025059256194235 Accuracy: 0.9217\n",
      "Epoch: 286\n",
      "Loss: 0.0004904441951538854 Accuracy: 0.922\n",
      "Epoch: 287\n",
      "Loss: 0.00044974965329652614 Accuracy: 0.9219\n",
      "Epoch: 288\n",
      "Loss: 0.00042330553177245226 Accuracy: 0.9213\n",
      "Epoch: 289\n",
      "Loss: 0.0004704807015143012 Accuracy: 0.9219\n",
      "Epoch: 290\n",
      "Loss: 0.000443557334193076 Accuracy: 0.922\n",
      "Epoch: 291\n",
      "Loss: 0.0004435763630495711 Accuracy: 0.9212\n",
      "Epoch: 292\n",
      "Loss: 0.00044449455489651587 Accuracy: 0.9218\n",
      "Epoch: 293\n",
      "Loss: 0.0004558681076207217 Accuracy: 0.9223\n",
      "Epoch: 294\n",
      "Loss: 0.0004472512082429603 Accuracy: 0.9215\n",
      "Epoch: 295\n",
      "Loss: 0.00043760282813086726 Accuracy: 0.9216\n",
      "Epoch: 296\n",
      "Loss: 0.0004823787409006808 Accuracy: 0.9217\n",
      "Epoch: 297\n",
      "Loss: 0.00045833285311141944 Accuracy: 0.9224\n",
      "Epoch: 298\n",
      "Loss: 0.00048213887990010445 Accuracy: 0.922\n",
      "Epoch: 299\n",
      "Loss: 0.0004534808365266998 Accuracy: 0.9219\n"
     ]
    }
   ],
   "source": [
    "train_loss,test_acc = train(0,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model accuracy: 0.9235\n"
     ]
    }
   ],
   "source": [
    "print('Best model accuracy:',max(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
